# src/infer_style_seq2seq.py
from pathlib import Path
from typing import Dict, List, Tuple

import torch
import re

# ê°™ì€ í´ë”ì— ìˆëŠ” train_style_seq2seq ë¥¼ ê·¸ëŒ€ë¡œ import
import train_style_seq2seq as train

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ê²½ë¡œ ì‚¬ìš©
MODEL_PATH: Path = train.MODEL_PATH        # models/style_seq2seq.pt
VOCAB_PATH: Path = train.VOCAB_PATH        # models/style_vocab.json


# ëª¨ë¸ + ë‹¨ì–´ì¥ ë¡œë“œ
def load_model() -> Tuple[torch.nn.Module, Dict[str, int], Dict[int, str]]:
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì‹œë„: {MODEL_PATH}")
    print(f"âœ… ë‹¨ì–´ì¥ ë¡œë“œ ì‹œë„: {VOCAB_PATH}")

    if not VOCAB_PATH.exists():
        raise FileNotFoundError(f"ë‹¨ì–´ì¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {VOCAB_PATH}")

    # train.py ì˜ load_vocab ê·¸ëŒ€ë¡œ ì‚¬ìš©
    token2idx, idx2token = train.load_vocab(VOCAB_PATH)
    print(f"âœ… ë‹¨ì–´ì¥ ë¡œë“œ ì™„ë£Œ (vocab_size={len(token2idx)})")

    pad_idx = token2idx[train.SPECIAL_TOKENS["PAD"]]

    encoder = train.EncoderRNN(
        vocab_size=len(token2idx),
        emb_size=train.EMBED_SIZE,
        hidden_size=train.HIDDEN_SIZE,
        pad_idx=pad_idx,
        num_layers=train.NUM_LAYERS,
    )
    decoder = train.DecoderRNN(
        vocab_size=len(token2idx),
        emb_size=train.EMBED_SIZE,
        hidden_size=train.HIDDEN_SIZE,
        pad_idx=pad_idx,
        num_layers=train.NUM_LAYERS,
    )
    model = train.Seq2Seq(encoder, decoder, pad_idx).to(DEVICE)

    if not MODEL_PATH.exists():
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")

    state = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(state)
    model.eval()
    print("âœ… Attention Seq2Seq ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    return model, token2idx, idx2token


# ë””ì½”ë”© + í›„ì²˜ë¦¬
@torch.no_grad()
def greedy_decode_min_eos(
    model: torch.nn.Module,
    src_text: str,
    token2idx: Dict[str, int],
    idx2token: Dict[int, str],
    device: torch.device,
    max_len: int = None,
    min_len: int = 5,
) -> str:
    # Attention Seq2Seq greedy decoding (+ ë°˜ë³µ ì–µì œ ë²„ì „)
    model.eval()

    if max_len is None:
        max_len = train.MAX_DECODE_LEN

    pad_idx = token2idx[train.SPECIAL_TOKENS["PAD"]]
    bos_idx = token2idx[train.SPECIAL_TOKENS["BOS"]]
    eos_idx = token2idx[train.SPECIAL_TOKENS["EOS"]]
    unk_idx = token2idx[train.SPECIAL_TOKENS["UNK"]]

    # ì¸ì½”ë” ì…ë ¥ ì¤€ë¹„
    src_ids = train.encode_sentence(src_text, token2idx, add_bos=True, add_eos=True)
    src_tensor = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(1)  # (src_len, 1)

    encoder_outputs, hidden = model.encoder(src_tensor)

    # ë””ì½”ë” ì‹œì‘: BOS
    input_step = torch.tensor([[bos_idx]], dtype=torch.long, device=device)
    generated: List[int] = []

    # Bigram ë°˜ë³µ ë°©ì§€ìš©
    seen_bigrams = set()

    for step in range(max_len):
        logits, hidden, _ = model.decoder(input_step, hidden, encoder_outputs)

        # ìƒìœ„ 10ê°œ í›„ë³´ ì¤‘ì—ì„œ ê·œì¹™ì— ë§ëŠ” ê²ƒ ê³ ë¥´ê¸°
        topv, topi = logits.topk(10, dim=1)  # (1, 10)

        chosen = None
        last_token = generated[-1] if generated else None

        for cand in topi[0]:
            ci = cand.item()

            # (1) ì´ˆë°˜ì—ëŠ” EOS í”¼í•˜ê¸°
            if step < min_len and ci == eos_idx:
                continue

            # (2) UNK / PAD / BOS í”¼í•˜ê¸°
            if ci in (unk_idx, pad_idx, bos_idx):
                continue

            # (3) ë°”ë¡œ ì§ì „ í† í°ê³¼ ê°™ìœ¼ë©´ í”¼í•˜ê¸° (ì—°ì† ë°˜ë³µ ë°©ì§€)
            if last_token is not None and ci == last_token:
                continue

            # (4) ìµœê·¼ bigram ë°˜ë³µ ë°©ì§€
            if last_token is not None:
                bg = (last_token, ci)
                if bg in seen_bigrams and step >= min_len:
                    continue

            chosen = ci
            break

        # ì „ë¶€ ê±¸ëŸ¬ì¡Œìœ¼ë©´ 1ë“± í›„ë³´ë¼ë„ ì‚¬ìš©
        if chosen is None:
            chosen = topi[0, 0].item()

        # EOS ì²˜ë¦¬
        if chosen == eos_idx and step >= min_len:
            break
        if chosen == eos_idx:
            # min_len ì „ì— EOSê°€ ë‚˜ì™”ìœ¼ë©´ ë¬´ì‹œí•˜ê³  ê³„ì†
            continue

        # bigram ê¸°ë¡
        if last_token is not None:
            seen_bigrams.add((last_token, chosen))

        generated.append(chosen)
        input_step = torch.tensor([[chosen]], dtype=torch.long, device=device)

    # ì¸ë±ìŠ¤ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë””ì½”ë”©
    raw_text = train.decode_indices(generated, idx2token)
    return raw_text

import re

def postprocess_text(text: str) -> str:
    # ë‹¨ìˆœ í›„ì²˜ë¦¬ ê°œì„  ë²„ì „
    s = text.strip()
    if not s:
        return s

    # 0) BPE í† í°( )ì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜ + ê³µë°± ì •ë¦¬
    s = s.replace(" ", " ")
    s = re.sub(r"\s+", " ", s).strip()
    if not s:
        return s

    # 1) ê°™ì€ ë‹¨ì–´ 3ë²ˆ ì´ìƒ ì—°ì† â†’ 2ë²ˆìœ¼ë¡œ ì¤„ì´ê¸°
    words = s.split()
    compressed = []
    prev = None
    repeat_cnt = 0
    for w in words:
        if w == prev:
            repeat_cnt += 1
            if repeat_cnt >= 2:
                continue
        else:
            prev = w
            repeat_cnt = 0
        compressed.append(w)

    s = " ".join(compressed).strip()
    if not s:
        return s

    # 2) ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë’¤, ì—°ì†ìœ¼ë¡œ ê°™ì€ ë¬¸ì¥ì€ 1ë²ˆë§Œ ë‚¨ê¹€
    parts = re.split(r"([\.!?])", s)
    sentences = []
    buf = ""

    for part in parts:
        if part in ".!?":
            buf += part
            if buf.strip():
                sentences.append(buf.strip())
            buf = ""
        else:
            buf += part

    if buf.strip():
        sentences.append(buf.strip())

    cleaned_sentences = []
    for sent in sentences:
        if not cleaned_sentences or cleaned_sentences[-1] != sent:
            cleaned_sentences.append(sent)

    s = " ".join(cleaned_sentences).strip()
    if not s:
        return s

    # 3) ë§¨ ëì— í•œ ê¸€ìì§œë¦¬ í† ë§‰(ì˜ˆ: 'ê²Œ', 'ë„¤', 'ìš”')ë§Œ ë©ê·¸ëŸ¬ë‹ˆ ìˆìœ¼ë©´ ì œê±°
    tokens = s.split()
    if len(tokens) >= 2 and len(tokens[-1]) == 1:
        if tokens[-2].endswith((".", "!", "?")):
            tokens = tokens[:-1]
            s = " ".join(tokens).strip()

    # 4) ëì— ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ ì—†ìœ¼ë©´ ë§ˆì¹¨í‘œ í•˜ë‚˜ ë¶™ì´ê¸°
    s = s.strip()
    if s and s[-1] not in ".!?":
        s += "."

    return s


# ì¸í„°ë™í‹°ë¸Œ UI
EMO_OPTIONS = {
    1: ("ê¸°ì¨", "E01"),
    2: ("ìŠ¬í””", "E02"),
    3: ("ë¶„ë…¸", "E18"),
    4: ("ë¶ˆì•ˆ", "E21"),  # ê¸°ë³¸
    5: ("ìƒì²˜", "E11"),
    6: ("ë‹¹í™©", "E31"),
}

CTX_OPTIONS = {
    1: ("ì¼ìƒ", "daily"),
    2: ("ì§„ë¡œ/í•™ì—…Â·ì—…ë¬´", "career"),
    3: ("ê´€ê³„/ê°€ì¡±Â·ì—°ì• ", "relation"),
    4: ("ê°ì •ìƒë‹´", "counsel"),
}
STYLE_OPTIONS = {
    1: ("í•´ìš”ì²´", "í•´ìš”ì²´"),
    2: ("ë°˜ë§ì²´", "ë°˜ë§ì²´"),
    3: ("í•©ì‡¼ì²´", "í•©ì‡¼ì²´"),
}


def select_option(prompt: str, options: Dict[int, Tuple[str, str]], default: int) -> Tuple[str, str]:
    while True:
        raw = input(prompt).strip()
        if raw == "":
            idx = default
        else:
            try:
                idx = int(raw)
            except ValueError:
                print("  â†’ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                continue
        if idx in options:
            return options[idx]
        print("  â†’ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•˜ì„¸ìš”.")


def main():
    model, token2idx, idx2token = load_model()

    print()
    print("=== ê°ì •/ìƒí™© ê¸°ë°˜ ë¬¸ì¥ ìŠ¤íƒ€ì¼ ë³€í™˜ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ (Attention Seq2Seq + ë°˜ë³µ ì–µì œ + í›„ì²˜ë¦¬) ===")
    print("ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´, ê°ì •/ìƒí™©/ë§íˆ¬ë¥¼ ê³¨ë¼ì„œ ë³€í™˜ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("â€» ì¶œë ¥ ë¬¸ì¥ì€ í•™ìŠµëœ Attention Seq2Seq ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,")
    print("   n-gram ë°˜ë³µì„ ì¤„ì´ëŠ” ë””ì½”ë”©/í›„ì²˜ë¦¬ ê·œì¹™ì„ ì ìš©í•œ ê²ƒì…ë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ ë¹ˆ ì¤„ì—ì„œ ì—”í„°ë¥¼ ëˆ„ë¥´ê±°ë‚˜ 'quit', 'q' ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print()

    while True:
        src = input("ğŸ‘‰ ë³€í™˜í•  ì›ë¬¸ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” : ").strip()
        if src == "" or src.lower() in ("quit", "q"):
            print("\n[ì¢…ë£Œ] ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ê°ì • ì„ íƒ
        print("\n[ê°ì • ì„ íƒ]")
        for k, (name, code) in EMO_OPTIONS.items():
            print(f"  {k}. {name}")
        emo_name, emo_code = select_option("ë²ˆí˜¸ ì„ íƒ (ì—”í„°=4: ë¶ˆì•ˆ) : ", EMO_OPTIONS, default=4)

        # ìƒí™© ì„ íƒ
        print("\n[ìƒí™©/ì»¨í…ìŠ¤íŠ¸ ì„ íƒ]")
        for k, (name, code) in CTX_OPTIONS.items():
            print(f"  {k}. {name}")
        ctx_name, ctx_code = select_option("ë²ˆí˜¸ ì„ íƒ (ì—”í„°=1: ì¼ìƒ) : ", CTX_OPTIONS, default=1)

        # ë§íˆ¬ ì„ íƒ
        print("\n[ë§íˆ¬(ìŠ¤íƒ€ì¼) ì„ íƒ]")
        for k, (name, code) in STYLE_OPTIONS.items():
            print(f"  {k}. {name}")
        style_name, style_code = select_option("ë²ˆí˜¸ ì„ íƒ (ì—”í„°=1: í•´ìš”ì²´) : ", STYLE_OPTIONS, default=1)

        # ëª¨ë¸ ì…ë ¥ ë¬¸ì¥ êµ¬ì„±
        model_input = f"<ctx:{ctx_code}> <emo:{emo_code}> <style:{style_code}> {src}"
        print("\n[ëª¨ë¸ ì…ë ¥]")
        print(f"  {model_input}")
        print(f"  - ìƒí™©: {ctx_name}")
        print(f"  - ê°ì •: {emo_name}")
        print(f"  - ë§íˆ¬: {style_name}\n")

        # ë””ì½”ë”©
        raw_out = greedy_decode_min_eos(
            model,
            model_input,
            token2idx,
            idx2token,
            DEVICE,
            max_len=40,
            min_len=5,
        )
        cleaned_out = postprocess_text(raw_out)

        print(f"ğŸ§  ëª¨ë¸ ì›ì¶œë ¥(Seq2Seq+Attention, min_len/ë°˜ë³µì œì–´ ì ìš© ì „) : {raw_out if raw_out else '(ë¹ˆ ë¬¸ìì—´)'}")
        print(f"âœ¨ ìµœì¢… ë³€í™˜ ê²°ê³¼(í›„ì²˜ë¦¬ ì ìš©) : {cleaned_out if cleaned_out else '(ì¶œë ¥í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.)'}")
        print()


if __name__ == "__main__":
    main()