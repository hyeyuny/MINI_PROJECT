import json
from pathlib import Path
from typing import Dict, List, Tuple

import torch
import torch.nn as nn

MODEL_PATH: Path = Path("models/style_seq2seq.pt")
VOCAB_PATH: Path = Path("models/style_vocab.json")

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

SPECIAL_TOKENS = {
    "PAD": "<pad>",
    "BOS": "<bos>",
    "EOS": "<eos>",
    "UNK": "<unk>",
}

EMBED_SIZE = 256
HIDDEN_SIZE = 512
NUM_LAYERS = 1
MAX_DECODE_LEN = 60


def load_vocab(path: Path) -> Tuple[Dict[str, int], Dict[int, str]]:
    with path.open(encoding="utf-8") as f:
        obj = json.load(f)
    token2idx: Dict[str, int] = obj["token2idx"]
    idx2token: Dict[int, str] = {idx: tok for tok, idx in token2idx.items()}
    return token2idx, idx2token


def tokenize(text: str) -> List[str]:
    return text.strip().split()


def encode_sentence(
    text: str,
    token2idx: Dict[str, int],
    add_bos: bool = True,
    add_eos: bool = True,
) -> List[int]:
    unk_idx = token2idx[SPECIAL_TOKENS["UNK"]]
    tokens = tokenize(text)
    ids: List[int] = []
    if add_bos:
        ids.append(token2idx[SPECIAL_TOKENS["BOS"]])
    for t in tokens:
        ids.append(token2idx.get(t, unk_idx))
    if add_eos:
        ids.append(token2idx[SPECIAL_TOKENS["EOS"]])
    return ids


def decode_indices(indices: List[int], idx2token: Dict[int, str]) -> str:
    tokens: List[str] = []
    for idx in indices:
        tok = idx2token.get(int(idx), SPECIAL_TOKENS["UNK"])
        if tok == SPECIAL_TOKENS["EOS"]:
            break
        if tok in (SPECIAL_TOKENS["BOS"], SPECIAL_TOKENS["PAD"]):
            continue
        tokens.append(tok)
    return " ".join(tokens).strip()


def is_repetitive(text: str) -> bool:
    tokens = [t for t in tokenize(text) if t not in [".", ",", "!", "?", "â€¦"]]
    if len(tokens) <= 1:
        return True
    unique = set(tokens)
    ratio = len(unique) / len(tokens)
    return ratio < 0.5


class EncoderRNN(nn.Module):
    def __init__(self, vocab_size: int, emb_size: int, hidden_size: int,
                 pad_idx: int, num_layers: int = 1):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=pad_idx)
        self.gru = nn.GRU(
            emb_size,
            hidden_size,
            num_layers=num_layers,
            bidirectional=False,
        )

    def forward(self, src: torch.Tensor):
        embedded = self.embedding(src)
        outputs, hidden = self.gru(embedded)
        return outputs, hidden


class LuongAttention(nn.Module):
    def __init__(self, hidden_size: int):
        super().__init__()
        self.hidden_size = hidden_size

    def forward(self, decoder_hidden: torch.Tensor, encoder_outputs: torch.Tensor):
        dec = decoder_hidden.permute(1, 0, 2)
        enc = encoder_outputs.permute(1, 0, 2)
        scores = torch.bmm(dec, enc.transpose(1, 2))
        attn_weights = torch.softmax(scores, dim=-1)
        context = torch.bmm(attn_weights, enc)
        context = context.squeeze(1)
        attn_weights = attn_weights.squeeze(1)
        return context, attn_weights


class DecoderRNN(nn.Module):
    def __init__(self, vocab_size: int, emb_size: int, hidden_size: int,
                 pad_idx: int, num_layers: int = 1):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=pad_idx)
        self.gru = nn.GRU(emb_size, hidden_size, num_layers=num_layers)
        self.attn = LuongAttention(hidden_size)
        self.fc = nn.Linear(hidden_size * 2, vocab_size)

    def forward(self,
                input_step: torch.Tensor,
                hidden: torch.Tensor,
                encoder_outputs: torch.Tensor):
        embedded = self.embedding(input_step)
        output, hidden = self.gru(embedded, hidden)
        context, attn_weights = self.attn(output, encoder_outputs)
        output = output.squeeze(0)
        concat = torch.cat([output, context], dim=1)
        logits = self.fc(concat)
        return logits, hidden, attn_weights


class Seq2Seq(nn.Module):
    def __init__(self, encoder: EncoderRNN, decoder: DecoderRNN, pad_idx: int):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder
        self.pad_idx = pad_idx


@torch.no_grad()
def decode_with_strategy(
    model: Seq2Seq,
    src_text: str,
    token2idx: Dict[str, int],
    idx2token: Dict[int, str],
    device: torch.device,
    max_len: int = MAX_DECODE_LEN,
) -> str:
    model.eval()

    pad_idx = token2idx[SPECIAL_TOKENS["PAD"]]
    bos_idx = token2idx[SPECIAL_TOKENS["BOS"]]
    eos_idx = token2idx[SPECIAL_TOKENS["EOS"]]
    unk_idx = token2idx[SPECIAL_TOKENS["UNK"]]

    src_ids = encode_sentence(src_text, token2idx, add_bos=True, add_eos=True)
    src_tensor = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(1)

    encoder_outputs, hidden = model.encoder(src_tensor)

    input_step = torch.tensor([[bos_idx]], dtype=torch.long, device=device)
    generated: List[int] = []

    for step in range(max_len):
        logits, hidden, _ = model.decoder(input_step, hidden, encoder_outputs)
        topv, topi = logits.topk(5, dim=1)

        chosen = None
        for cand in topi[0]:
            ci = cand.item()
            if ci == eos_idx and len(generated) < 3:
                continue
            if ci in (pad_idx, bos_idx):
                continue
            if len(generated) >= 2 and ci == generated[-1]:
                continue
            if len(generated) >= 3 and generated[-2:] == [generated[-3], ci]:
                continue
            chosen = ci
            break

        if chosen is None:
            chosen = topi[0, 0].item()

        if chosen == eos_idx:
            break

        generated.append(chosen)
        input_step = torch.tensor([[chosen]], dtype=torch.long, device=device)

    return decode_indices(generated, idx2token)


def interactive_loop(model: Seq2Seq, token2idx: Dict[str, int], idx2token: Dict[int, str]):
    emo_map = {
        1: "E01",
        2: "E02",
        3: "E03",
        4: "E04",
        5: "E05",
        6: "E06",
    }

    ctx_map = {
        1: "daily",
        2: "career",
        3: "relationship",
        4: "counsel",
    }

    style_map = {
        1: "í•´ìš”ì²´",
        2: "ë°˜ë§ì²´",
        3: "í•©ì‡¼ì²´",
    }

    print("\n=== ê°ì •/ìƒí™© ê¸°ë°˜ ë¬¸ì¥ ìŠ¤íƒ€ì¼ ë³€í™˜ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ ===")
    print("ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´, ê°ì •/ìƒí™©/ë§íˆ¬ë¥¼ ê³¨ë¼ì„œ ë³€í™˜ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ ë¹ˆ ì¤„ì—ì„œ ì—”í„°ë¥¼ ëˆ„ë¥´ê±°ë‚˜ 'quit', 'q' ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

    while True:
        src = input("ğŸ‘‰ ë³€í™˜í•  ì›ë¬¸ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” : ").strip()
        if src == "" or src.lower() in ("quit", "q"):
            print("\n[ì¢…ë£Œ] ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        print("\n[ê°ì • ì„ íƒ]")
        print("  1. ê¸°ì¨")
        print("  2. ìŠ¬í””")
        print("  3. ë¶„ë…¸")
        print("  4. ë¶ˆì•ˆ")
        print("  5. ìƒì²˜")
        print("  6. ë‹¹í™©")
        emo_in = input("ë²ˆí˜¸ ì„ íƒ (ì—”í„°=1: ê¸°ì¨) : ").strip()
        emo_choice = 1 if emo_in == "" else max(1, min(6, int(emo_in)))
        emo_tag = emo_map[emo_choice]

        print("\n[ìƒí™©/ì»¨í…ìŠ¤íŠ¸ ì„ íƒ]")
        print("  1. ì¼ìƒ")
        print("  2. ì§„ë¡œ/í•™ì—…Â·ì—…ë¬´")
        print("  3. ê´€ê³„/ê°€ì¡±Â·ì—°ì• ")
        print("  4. ê°ì •ìƒë‹´")
        ctx_in = input("ë²ˆí˜¸ ì„ íƒ (ì—”í„°=1: ì¼ìƒ) : ").strip()
        ctx_choice = 1 if ctx_in == "" else max(1, min(4, int(ctx_in)))
        ctx_tag = ctx_map[ctx_choice]

        print("\n[ë§íˆ¬(ìŠ¤íƒ€ì¼) ì„ íƒ]")
        print("  1. í•´ìš”ì²´")
        print("  2. ë°˜ë§ì²´")
        print("  3. í•©ì‡¼ì²´")
        style_in = input("ë²ˆí˜¸ ì„ íƒ (ì—”í„°=1: í•´ìš”ì²´) : ").strip()
        style_choice = 1 if style_in == "" else max(1, min(3, int(style_in)))
        style_tag = style_map[style_choice]

        control_prefix = f"<ctx:{ctx_tag}> <emo:{emo_tag}> <style:{style_tag}>"
        model_input = f"{control_prefix} {src}".strip()

        print("\n[ëª¨ë¸ ì…ë ¥]")
        print(f"  {model_input}")
        print(f"  - ìƒí™©: {['ì¼ìƒ','ì§„ë¡œ/í•™ì—…Â·ì—…ë¬´','ê´€ê³„/ê°€ì¡±Â·ì—°ì• ','ê°ì •ìƒë‹´'][ctx_choice-1]}")
        print(f"  - ê°ì •: {['ê¸°ì¨','ìŠ¬í””','ë¶„ë…¸','ë¶ˆì•ˆ','ìƒì²˜','ë‹¹í™©'][emo_choice-1]}")
        print(f"  - ë§íˆ¬: {style_tag}")

        raw_out = decode_with_strategy(model, model_input, token2idx, idx2token, DEVICE)

        print("\nğŸ§  ëª¨ë¸ ì¶œë ¥ :", raw_out if raw_out else "(ë¹ˆ ë¬¸ì¥)")

        if (not raw_out) or is_repetitive(raw_out):
            print("âš ï¸ ëª¨ë¸ì´ ì¶œë ¥ì„ ì œëŒ€ë¡œ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ë°˜ë³µ ë˜ëŠ” ë¹„ì •ìƒ ì¶œë ¥ìœ¼ë¡œ íŒë‹¨)\n")
        else:
            print("âœ¨ ìµœì¢… ë³€í™˜ ê²°ê³¼ :", raw_out, "\n")


def main():
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì‹œë„: {MODEL_PATH}")
    print(f"âœ… ë‹¨ì–´ì¥ ë¡œë“œ ì‹œë„: {VOCAB_PATH}")

    if not MODEL_PATH.exists():
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
    if not VOCAB_PATH.exists():
        raise FileNotFoundError(f"ë‹¨ì–´ì¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VOCAB_PATH}")

    token2idx, idx2token = load_vocab(VOCAB_PATH)
    vocab_size = len(token2idx)
    print(f"âœ… ë‹¨ì–´ì¥ ë¡œë“œ ì™„ë£Œ (vocab_size={vocab_size})")

    pad_idx = token2idx[SPECIAL_TOKENS["PAD"]]

    encoder = EncoderRNN(vocab_size, EMBED_SIZE, HIDDEN_SIZE, pad_idx, NUM_LAYERS)
    decoder = DecoderRNN(vocab_size, EMBED_SIZE, HIDDEN_SIZE, pad_idx, NUM_LAYERS)
    model = Seq2Seq(encoder, decoder, pad_idx).to(DEVICE)

    state = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(state)
    print("âœ… Attention Seq2Seq ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    interactive_loop(model, token2idx, idx2token)


if __name__ == "__main__":
    main()
